# Мониторинг и логирование

* [Основы мониторинга](#Основы-мониторинга)
* [Основы сбора и обработки логов](#Основы-сбора-и-обработки-логов)

## <a id="Основы-мониторинга">Основы мониторинга</a>

```txt
1 - Понятие метрики, отличие метрик от логов.
2 - Обзор и сравнение инструментов мониторинга (Zabbix, Prometheus).
3 - Основы Grafana
```

### Notice-1

```txt
1 - Чем отличается лог от метрики? Примеры метрик.

->  Лог - это запись события, произошедшего в системе, содержащая информацию о времени, 
    дате, типе события и других подробностях. Логи обычно используются для отслеживания и
    анализа событий, произошедших в системе, таких как ошибки, предупреждения, информационные
    сообщения и т.п. Логи могут быть использованы для:

    - Отслеживания ошибок и исключений
    - Анализа производительности системы
    - Выявления проблем с безопасностью
    - Мониторинга системы в режиме реального времени

    Метрика - это числовое значение, характеризующее определённый аспект системы, которое
    позволяет оценить ее производительность, эффективность и другие характеристики. Метрики
    обычно используются для мониторинга и анализа системы в режиме реального времени, а также
    для выявления тенденций и закономерностей.

    Примеры метрик:
    - CPU usage (загрузка процессора) - показывает, какую часть процессорного времени занимает
    система
    - Memory usage (загрузка памяти) - показывает, сколько памяти занимает система
    - Request per second (количество запросов в секунду) - показывает, сколько запросов система
    обрабатывает в секунду
    - Response time (время ответа) - показывает, сколько времени система тратит на обработку
    запроса
    - Error rate (коэффициент ошибок) - показывает, сколько ошибок система выдает на единицу
    времени
    - Disk usage (загрузка диска) - показывает, сколько места на диске занимает система
    - Network traffic (трафик сети) - показывает, сколько данных система передает и принимает
    по сети
    - Uptime (время работы) - показывает, сколько времени система работает без перезагрузки
    - Downtime (время простоя) - показывает, сколько времени система простаивает

    Метрики можно разделить на несколько категорий:
    - Производительность (performance) - метрики, характеризующие скорость и эффективность
    системы
    - Ресурсы (resources) - метрики, характеризующие использование системных ресурсов, таких
    как процессор, память, диск и т.п.
    - Ошибки (errors) - метрики, характеризующие количество и тип ошибок в системе
    - Безопасность (security) - метрики, характеризующие безопасность системы и выявляющие
    потенциальные угрозы
    - Утилизация (utilization) - метрики, характеризующие использование системных ресурсов,
    таких как процессор, память, диск и т.п

    Метрики можно использовать для:
    - Мониторинга системы в режиме реального времени
    - Анализа производительности системы
    - Выявления проблем с безопасностью
    - Оптимизации системы для повышения производительности и эффективности
    - Планирования и прогнозирования потребностей системы
```

### Intern-1

```txt
1 - Чем отличаются Zabbix и Prometheus?

->  Zabbix и Prometheus - это два популярных инструмента для мониторинга и сбора метрик. 
    
    Основные отличия между ними:
    1- Архитектура:
    - Zabbix: централизованная архитектура, где сервер Zabbix собирает данные от агентов,
    установленных на мониторимых хостах. Агенты могут быть установлены на различных
    операционных системах, включая Windows, Linux и macOS.
    - Prometheus: распределенная архитектура, где сервер Prometheus собирает данные от
    экспортеров, которые могут быть установлены на мониторимых хостах или работать как
    отдельные сервисы. Экспортеры могут быть написаны на различных языках программирования,
    включая Go, Java и Python.

    2 - Сбор данных:
    - Zabbix: использует пуш-модель, где агенты отправляют данные на сервер Zabbix. Это
    означает, что агенты периодически отправляют данные на сервер, который затем обрабатывает
    и хранит их.
    - Prometheus: использует пул-модель, где сервер Prometheus запрашивает данные у
    экспортеров. Это означает, что сервер периодически отправляет запросы на экспортеры,
    которые затем отправляют данные на сервер.

    3 - Хранение данных:
    - Zabbix: использует реляционную базу данных (например, MySQL) для хранения данных. Это
    означает, что данные хранятся в таблицах, которые можно запросить и обработать с помощью
    SQL.
    - Prometheus: использует собственную базу данных, основанную на времени (time-series
    database) для хранения данных. Это означает, что данные хранятся в виде временных рядов,
    которые можно запросить и обработать с помощью PromQL.

    4 - Масштабируемость:
    - Zabbix: рассчитан на средние и большие системы, но может быть менее эффективен для
    очень больших систем. Это связано с тем, что Zabbix использует централизованную
    архитектуру, которая поможет при обработке большого количества данных.
    - Prometheus: рассчитан на большие и распределенные системы, легко масштабируется и
    может обрабатывать данных. Это связано с тем, что Prometheus использует распределенную
    архитектуру, которая позволяет ему легко масштабироваться и обрабатывать данные в реальном
    времени.

    5 - Функциональность:
    - Zabbix: предоставляет широкий спектр функций, включая обнаружение проблем, отправку
    уведомлений, создание отчетов и т.п. Это означает, что Zabbix можно использовать не только
    для сбора метрик, но и для мониторинга и управления системами.
    - Prometheus: специализируется на сборе и хранении метрик, но может быть интегрирован с
    другими инструментами для расширения функциональности. Это означает, что Prometheus можно
    использовать в качестве основы для построения более сложных систем мониторинга и управления.

    6 - Сообщество:
    - Zabbix: имеет большое и активное сообщество, с множеством плагинов и интеграций. Это
    означает, что пользователи Zabbix могут найти множество ресурсов и инструментов для
    расширения функциональности системы.
    - Prometheus: также имеет большое и активное сообщество, но более ориентированное на
    разработчиков и операторов. Это означает, что пользователи Prometheus могут найти множество
    ресурсов и инструментов для расширения функциональности системы, но могут потребоваться
    более глубокие знания в области программирования и системного администрирования.

    В целом, Zabbix подходит для систем, которые требуют централизованного управления и
    широкого спектра функций, а Prometheus - для систем, которые требуют высокой
    масштабируемости и специализированного сбора метрик. Однако, оба инструмента могут быть
    использованы в различных сценариях и могут быть интегрированы друг с другом для построения
    более сложных систем мониторинга и управления.
```

```txt
2 - Что такое Grafana? Какие источники данных она поддерживает?

->  Инструмент - Grafana предоставляет следующие возможности:
    - Визуализация данных: Grafana позволяет создавать различные типы графиков и диаграмм для
    визуализации данных, включая линейные графики, столбчатые графики, круговые диаграммы и
    другие.
    - Интерактивные панели: Grafana позволяет создавать интерактивные панели мониторинга,
    которые можно настраивать и конфигурировать в соответствии с потребностями пользователя.
    - Поддержка различных источников данных: Grafana поддерживает широкий спектр источников
    данных, включая базы данных, сервисы мониторинга и другие системы.
    - Возможность создавать пользовательские панели: Grafana позволяет создавать
    пользовательские панели мониторинга, которые можно настраивать и конфигурировать в
    соответствии с потребностями пользователя.
    - Возможность экспортировать данные: Grafana позволяет экспортировать данные в различные
    форматы, включая CSV, JSON и другие.

    Grafana также предоставляет следующие функции:
    - Динамическая визуализация: Grafana позволяет создавать динамические графики и диаграммы,
    которые можно обновлять в режиме реального времени.
    - Интерактивные фильтры: Grafana позволяет создавать интерактивные фильтры, которые можно
    использовать для фильтрации данных и создания пользовательских панелей мониторинга.
    - Возможность создавать пользовательские плагины: Grafana позволяет создавать
    пользовательские плагины, которые можно использовать для расширения функциональности
    инструмента.
    - Поддержка различных типов данных: Grafana поддерживает различные типы данных, включая
    числовые данные, текстовые данные и другие.
    - Возможность создавать пользовательские темы: Grafana позволяет создавать пользовательские
    темы, которые можно использовать для настройки внешнего вида и поведения инструмента.

    Grafana является популярным инструментом для мониторинга и визуализации данных, и его можно
    использовать в различных сценариях, включая мониторинг систем, сервисов и приложений.
    Grafana также можно использовать для создания пользовательских панелей мониторинга, которые
    можно настраивать и конфигурировать в соответствии с потребностями пользователя.

    Grafana имеет следующие преимущества:
    - Легкость использования: Grafana имеет интуитивно понятный интерфейс, который позволяет
    легко создавать и настраивать панели мониторинга.
    - Гибкость: Grafana поддерживает широкий спектр источников данных и позволяет создавать
    пользовательские панели мониторинга.
    - Масштабируемость: Grafana можно использовать для мониторинга больших систем и сервисов.
    - Безопасность: Grafana имеет встроенную поддержку безопасности, которая позволяет
    контролировать доступ к данным и панелям мониторинга.

    Источники:
    - Prometheus: Grafana имеет тесную интеграцию с Prometheus, что позволяет использовать его
    как источник данных для создания панелей мониторинга.
    - Graphite инструмент для сбора и хранения метрик.
    - InfluxDB/OpenTSDB: база данных, специализированной для хранения временных рядов данных.
    - Elasticsearch: инструмент для поиска и анализа данных.
    - MySQL/PostgreSQL/Microsoft SQL Server/Oracle
    - AWS CloudWatch: Grafana поддерживает AWS CloudWatch, который является сервисом
    мониторинга и управления для облачных ресурсов Amazon Web Services.
    - Google Cloud Monitoring: Grafana поддерживает Google Cloud Monitoring, который является
    сервисом мониторинга и управления для облачных ресурсов Google Cloud Platform.
    - Azure Monitor: Grafana поддерживает Azure Monitor, который является сервисом мониторинга
    и управления для облачных ресурсов Microsoft Azure.
```

### Advanced-1

```txt
1 - Как установить и настроить zabbix-агент?

->  1 - Чтобы установить Zabbix-агент, вам нужно скачать и установить пакет Zabbix-агента для 
    вашей операционной системы. Для Linux-систем вы можете использовать команду apt-get или
    yum для установки пакета.

    sudo apt-get update
    sudo apt-get install zabbix-agent
    sudo yum install zabbix-agent

    2 - После установки Zabbix-агента вам нужно настроить его для работы с вашим
    Zabbix-сервером. Для этого вам нужно создать файл конфигурации Zabbix-агента (клиент)

    sudo nano /etc/zabbix/zabbix_agentd.conf

    - Server: IP-адрес или имя хоста вашего Zabbix-сервера.
    - ServerActive: IP-адрес или имя хоста вашего Zabbix-сервера, который будет использоваться
    для активного опроса агента.
    - Hostname: имя хоста, которое будет использоваться для идентификации агента на
    Zabbix-сервере.
                                Server=192.168.1.100
                                ServerActive=192.168.1.100
                                Hostname=myhost
    
    3 - После настройки Zabbix-агента вам нужно запустить его. Для этого вы можете использовать
    команду service или systemctl

    sudo service zabbix-agent start
    sudo systemctl start zabbix-agent

    4 - После запуска Zabbix-агента вам нужно проверить его работу. Для этого вы можете
    использовать команду zabbix_get для получения данных с агента.

    zabbix_get -s 192.168.1.100 -k "system.cpu.load[1min]"

    5 - После проверки работы Zabbix-агента вам нужно добавить его на Zabbix-сервер.
    Для этого вы можете использовать веб-интерфейс Zabbix-сервера.
    Например, вы можете перейти на страницу "Устройства" и нажать кнопку "Добавить устройство".
    Затем вы можете указать имя хоста, IP-адрес и другие параметры агента.
    После добавления агента на Zabbix-сервер вы можете начать мониторинг вашей инфраструктуры
    с помощью Zabbix
```

```txt
2 - Что такое Prometheus Exporter?

->  Prometheus Exporter - это программный компонент, который позволяет экспортировать метрики
    из различных систем и сервисов в формате Prometheus. Это позволяет использовать Prometheus
    для мониторинга и анализа данных из различных источников.

    Prometheus Exporter работает как промежуточный слой между системой или сервисом, который
    генерирует метрики, и Prometheus-сервером, который собирает и хранит эти метрики. Exporter
    получает метрики из системы или сервиса и преобразует их в формат Prometheus, который затем
    может быть собран Prometheus-сервером.

    Prometheus Exporter может быть использован для экспорта метрик из различных систем и
    сервисов, таких как:
    - Веб-серверы (например, Apache, Nginx)
    - Базы данных (например, MySQL, PostgreSQL)
    - Системы хранения данных (например, Redis, Memcached)
    - Системы управления контейнерами (например, Docker)
    - Системы мониторинга и управления (например, Nagios, Zabbix)

    Prometheus Exporter может быть реализован в различных формах, таких как:
    - Программа, которая запускается на стороне клиента и экспортирует метрики в формате
    Prometheus
    - Библиотека, которая может быть интегрирована в существующее приложение или сервис для
    экспорта метрик
    - Сервис, который работает как отдельный процесс и экспортирует метрики в формате
    Prometheus

    Преимущества использования Prometheus Exporter включают:
    - Упрощение процесса мониторинга и анализа данных из различных источников
    - Возможность использования Prometheus для мониторинга и анализа данных из различных
    систем и сервисов
    - Увеличение гибкости и масштабируемости системы мониторинга и анализа данных

    Некоторые примеры Prometheus Exporter включают:
    - Prometheus Node Exporter: экспортирует метрики о состоянии узла, такие как загрузка
    процессора, использование памяти и т. д.
    - Prometheus MySQL Exporter: экспортирует метрики о состоянии базы данных MySQL, такие как
    количество запросов, время ответа и т. д.
    - Prometheus Redis Exporter: экспортирует метрики о состоянии системы хранения данных
    Redis, такие как количество ключей, время ответа и т. д.

```

```txt
3 - Что такое Prometheus Pushgateway?

->  Prometheus Pushgateway - это компонент Prometheus, который позволяет отправлять метрики из
    различных систем и сервисов в Prometheus-сервер. Pushgateway работает как промежуточный
    слой между системой или сервисом, который генерирует метрики, и Prometheus-сервером,
    который собирает и хранит эти метрики.

    Pushgateway позволяет отправлять метрики в Prometheus-сервер в режиме реального времени,
    что позволяет использовать Prometheus для мониторинга и анализа данных из различных
    источников. Pushgateway также позволяет отправлять метрики из систем и сервисов, которые
    не поддерживают протокол Prometheus, что позволяет использовать Prometheus для мониторинга
    и анализа данных из различных источников.

    Pushgateway работает следующим образом:
    - Система или сервис, который генерирует метрики, отправляет эти метрики в Pushgateway.
    - Pushgateway принимает метрики и преобразует их в формат Prometheus.
    - Pushgateway отправляет метрики в Prometheus-сервер.
    - Prometheus-сервер собирает и хранит метрики.

    Преимущества использования Pushgateway включают:
    - Упрощение процесса мониторинга и анализа данных из различных источников
    - Возможность использования Prometheus для мониторинга и анализа данных из различных
    систем и сервисов
    - Увеличение гибкости и масштабируемости системы мониторинга и анализа данных

    Некоторые примеры использования Pushgateway включают:
    - Отправка метрик из системы мониторинга Nagios в Prometheus-сервер
    - Отправка метрик из системы управления контейнерами Docker в Prometheus-сервер
    - Отправка метрик из системы хранения данных Redis в Prometheus-сервер

    Pushgateway поддерживает следующие протоколы:
    - HTTP
    - HTTPS
    - gRPC

    Pushgateway также поддерживает следующие форматы метрик:
    - Prometheus
    - OpenMetrics

    Pushgateway можно использовать в различных сценариях, таких как:
    - Мониторинг и анализ данных из различных систем и сервисов
    - Упрощение процесса мониторинга и анализа данных
    - Увеличение гибкости и масштабируемости системы мониторинга и анализа данных.
```

## <a id="Основы-сбора-и-обработки-логов">Основы сбора и обработки логов</a>

```txt
1 - Уровни логирования.
2 - Обзор и сравнение ПО для сбора логов (log shippers): filebeat, fluentd, fluent bit, promtail.
3 - Обзор и сравнение ПО для хранение и обработки логов: Elasticsearch, Grafana Loki.
4 - Работа с логами контейнеров.
5 - Сбор логов в Kubernetes.
```

### Notice-2

```txt
1 - Какие бывают уровни логирования?

->  1 - DEBUG (отладка)
    самые подробные сообщения, обычно используются при разработке и отладке приложения.
    Пример: "Выполнен запрос к базе данных с параметрами: ..."

    2 - INFO (информация)
    сообщения о важных событиях в работе приложения.
    Пример: "Пользователь авторизовался успешно"

    3 - WARN (предупреждение)
    сообщения о потенциальных проблемах или необычных ситуациях.
    Пример: "Недостаточно места на диске для записи файла"

    4 - ERROR (ошибка)
    сообщения об ошибках, которые произошли во время работы приложения.
    Пример: "Ошибка при подключении к базе данных: ..."

    5 - FATAL (критическая ошибка)
    сообщения об ошибках, которые привели к критической неисправности приложения.
    Пример: "Приложение не может продолжить работу из-за ошибки в конфигурации"

    Эти уровни логирования помогают разработчикам и администраторам быстро определить
    серьезность проблемы и принять соответствующие меры.
```

```txt
2 - Что включает в ELK-stack?

->  ELK-stack (Elastic Stack) - это набор инструментов для сбора, обработки и визуализации
    логов и других данных. В него входят:

    - Elasticsearch (E): поисковый движок и хранилище данных, которое позволяет хранить и
    быстро искать лог-данные. Elasticsearch позволяет хранить большие объемы данных и
    обеспечивает быстрый поиск и фильтрацию данных. Он также поддерживает различные типы
    данных, такие как текст, числа, даты и т. д.

    - Logstash (L): инструмент для сбора, обработки и передачи лог-данных в Elasticsearch.
    Logstash может собирать данные из различных источников, таких как файлы, базы данных,
    сообщения и т. д. и передавать их в Elasticsearch для хранения и анализа. Logstash также
    поддерживает различные плагины для обработки и фильтрации данных.

    - Kibana (K): веб-интерфейс для визуализации и анализа лог-данных, хранящихся в
    Elasticsearch. Kibana позволяет создавать различные типы визуализаций, такие как графики,
    таблицы и карты, для анализа и понимания лог-данных. Kibana также поддерживает различные
    типы диаграмм и отчетов.

    Вместе эти инструменты позволяют:
    - Собирать лог-данные из различных источников с помощью Logstash
    - Обрабатывать и фильтровать лог-данные с помощью Logstash
    - Хранить лог-данные в поисковом движке Elasticsearch
    - Визуализировать и анализировать лог-данные с помощью Kibana
    - Выполнять поиск и фильтрацию лог-данных с помощью Elasticsearch
    - Создавать различные типы отчетов и диаграмм с помощью Kibana
    - Мониторить и анализировать лог-данные в режиме реального времени
```

```txt
3 - Что такое logstash? Зачем он нужен? Какие есть преимущества и недостатки при его 
    использовании?

->  Logstash - это инструмент для сбора, обработки и передачи лог-данных в различные системы
    хранения и анализа. Он является частью ELK-stack (Elastic Stack) и используется для
    обработки лог-данных из различных источников, таких как файлы, базы данных, сообщения и т.д.

    Logstash нужен для:
    - Сбора лог-данных из различных источников
    - Обработки и фильтрации лог-данных
    - Передачи лог-данных в системы хранения и анализа, такие как Elasticsearch
    - Упрощения процесса анализа и визуализации лог-данных

    Преимущества использования Logstash
    - Универсальность: Logstash может собирать лог-данные из различных источников и передавать
    их в различные системы хранения и анализа.
    - Гибкость: Logstash позволяет настраивать обработку и фильтрацию лог-данных в соответствии
    с потребностями пользователя.
    - Высокая производительность: Logstash может обрабатывать большие объемы лог-данных и
    передавать их в системы хранения и анализа в режиме реального времени.
    - Интеграция с ELK-stack: Logstash является частью ELK-stack и может быть использован для
    обработки лог-данных перед их передачей в Elasticsearch и визуализацией в Kibana.

    Недостатки использования Logstash
    - Сложность настройки: Logstash требует настройки и конфигурации для обработки
    лог-данных из различных источников.
    - Требуется знания: Logstash требует знаний о лог-данных, обработке и фильтрации
    данных, а также о системах хранения и анализа.
    - Ресурсоемкость: Logstash может потреблять значительные ресурсы системы, особенно при
    обработке больших объемов лог-данных.
    - Ограничения в обработке данных: Logstash имеет ограничения в обработке данных, особенно
    при работе с большими объемами данных
```

```txt
4 - Что такое fliebit (Filebeat)? Что такое fluent bit? Чем они отличаются? 

->  Filebeat и Fluent Bit - это два популярных агента сбора логов, которые помогают собирать, 
    обрабатывать и передавать логи из различных источников в системы мониторинга, аналитики и 
    хранения.

    Filebeat - это агент сбора логов от Elastic, который специально разработан для работы с
    экосистемой Elastic (Elasticsearch, Kibana, Logstash). Он собирает логи из файлов,
    системных журналов и других источников и передает их в Elasticsearch, Logstash или другие
    системы для дальнейшей обработки и анализа.

    Fluent Bit - это легковесный и гибкий агент сбора логов, который может собирать логи из
    различных источников, таких как файлы, системные журналы, Docker, Kubernetes и другие. Он
    поддерживает множество выходных плагинов, которые позволяют передавать логи в различные
    системы, включая Elasticsearch, Kafka, AWS CloudWatch, Google Cloud Logging и другие.

    Основные отличия между Filebeat и Fluent Bit:
    - Filebeat тесно интегрирован с экосистемой Elastic и предназначен для работы с
    Elasticsearch и Logstash.
    - Filebeat имеет более широкие возможности по обработке логов, включая фильтрацию, парсинг
    и обогащение логов.
    - Fluent Bit более универсален и может работать с различными системами, включая не только
    Elastic, но и другие системы мониторинга и аналитики.
    - Fluent Bit более легковесен и требует меньше ресурсов, что делает его более подходящим для
    работы в средах с ограниченными ресурсами.
```

### Intern-2

```txt
1 - Чем fluent bit отличается от fluentd?

->  Fluent Bit и Fluentd - это два популярных агента сбора логов, которые разработаны
    компанией Treasure Data. Они оба предназначены для сбора, обработки и передачи логов из
    различных источников в системы мониторинга, аналитики и хранения.

    Основные отличия между Fluent Bit и Fluentd:
    - Архитектура: Fluentd - это более старый и более сложный агент, который имеет модульную
    архитектуру и поддерживает множество плагинов. Fluent Bit - это более легковесный и гибкий
    агент, который имеет более простую архитектуру и поддерживает меньшее количество плагинов.
    - Производительность: Fluent Bit более быстрый и эффективный, чем Fluentd, особенно при
    работе с большими объемами логов.
    - Потребление ресурсов: Fluent Bit требует меньше ресурсов, чем Fluentd, что делает его
    более подходящим для работы в средах с ограниченными ресурсами.
    - Конфигурация: Fluent Bit имеет более простую конфигурацию, чем Fluentd, что делает его
    более легко настраиваемым.
    - Поддержка протоколов: Fluent Bit поддерживает меньшее количество протоколов, чем
    Fluentd, но все же поддерживает большинство популярных протоколов, таких как TCP, UDP,
    HTTP и другие.
    - Размер: Fluent Bit более компактный, чем Fluentd, что делает его более легко
    развертываемым в контейнерах и других средах.

    В целом, Fluent Bit - это более современный и более эффективный агент сбора логов, который
    предназначен для работы в современных средах с ограниченными ресурсами. Fluentd - это более
    старый и более сложный агент, который все еще может быть полезен в некоторых случаях, но
    требует более сложной конфигурации и более ресурсоемкий.

    <source>
      @type tail
      path /var/log/apache2/access.log
      pos_file /var/log/apache2/access.log.pos
      tag apache.access
    </source>
    <match apache.access>
      @type elasticsearch
      host localhost
      port 9200
      index_name apache_access
    </match>

    [INPUT]
      Name        tail
      Tag         apache_access
      Path        /var/log/apache2/access.log  
    [OUTPUT]
      Name        elasticsearch
      Match       apache_access
      Host        localhost
      Port        9200
      Index       apache_access
```

```txt
2 - Что такое Grafana Loki?

->  Grafana Loki - это система сбора и хранения логов, разработанная компанией Grafana Labs.
    Loki предназначена для сбора, обработки и хранения логов из различных источников, таких как
    приложения, сервисы и инфраструктура.

    Loki была создана как альтернатива традиционным системам сбора логов, таким как ELK
    (Elasticsearch, Logstash, Kibana) и Splunk. Основными целями Loki являются:
    - Упрощение сбора логов: Loki позволяет легко собирать логи из различных источников,
    используя простые и гибкие конфигурации.
    - Уменьшение стоимости хранения: Loki использует компактное хранение логов, что позволяет
    уменьшить стоимость хранения и увеличить скорость доступа к логам.
    - Улучшение производительности: Loki оптимизирована для высоких нагрузок и может
    обрабатывать большие объемы логов в режиме реального времени.

    Loki состоит из следующих компонентов:
    - Loki Server: центральный сервер, который собирает и хранит логи.
    - Loki Agent: агент, который собирает логи с источников и отправляет их на сервер Loki.
    - Grafana: веб-интерфейс, который позволяет просматривать и анализировать логи.

    Loki поддерживает следующие функции:
    - Сбор логов: Loki может собирать логи из различных источников, таких как файлы, системные
    журналы, Docker, Kubernetes и другие.
    - Обработка логов: Loki может обрабатывать логи, используя фильтры, парсеры и другие плагины.
    - Хранение логов: Loki хранит логи в компактном формате, что позволяет уменьшить стоимость
    хранения.
    - Поиск и фильтрация: Loki позволяет быстро искать и фильтровать логи, используя различные
    критерии.
    - Визуализация: Loki интегрируется с Grafana, что позволяет просматривать и анализировать
    логи в виде графиков и таблиц.
```

```txt
3 - Как настроить автоматический сбор логов из всех Docker-контейнеров (уже запущенных и новых)
    на определенном хосте и отправку этих логов в Elasticsearch?
    
->  1 - Берем docker-compose.yml
    version: '3'
    services:
        filebeat:
            image: docker.elastic.co/beats/filebeat:7.10.2
            volumes:
                - ./filebeat.yml:/usr/share/filebeat/filebeat.yml
                - /var/lib/docker/containers:/var/lib/docker/containers
            depends_on:
                - elasticsearch
            restart: always

        elasticsearch:
            image: docker.elastic.co/elasticsearch/elasticsearch:7.10.2
            environment:
                - xpack.security.enabled=false
            restart: always
    
    2 - Создание файла filebeat.yml
    filebeat.inputs:
        - type: docker
          containers:
          path: "/var/lib/docker/containers"
          scan_frequency: 10s
          json: true

    output.elasticsearch:
        hosts: ["elasticsearch:9200"]
        index: "docker-logs-%{[agent.version]}-%{+yyyy.MM.dd}"
    Этот файл конфигурации Filebeat указывает на то, что Filebeat должен собирать логи из всех Docker-контейнеров, расположенных в /var/lib/docker/containers, и отправлять их в
    Elasticsearch на порту 9200.

    3 - docker-compose up -d

    4 - docker-compose exec filebeat filebeat -e -c /usr/share/filebeat/filebeat.yml
    Эта команда запустит Filebeat в режиме отладки и выведет логи в консоль.
    5 - Вы можете проверить логи в Elasticsearch, используя команду:
    curl -XGET 'http://localhost:9200/_search?pretty'
    Эта команда выведет список всех логов, собранных Filebeat.
```

### Advanced-2

```txt
1 - Как реализовать автоматический сбор логов и всех подов/контейнеров в Kubernetes?

->  Можно сразу установить helm-овый чарт
    curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
    helm install efk stable/efk
    Немного поиграться с values, но подход слишком простой, плюс нужно объяснить что откуда.

    Второй вариант последовательно все устанавливать, как делал я. Пишем манифесты под эластик
    и кибану. Можем реализовать через sts эластик, также сделаем pv чтобы был claim. Связываем
    кибану и эластик через env, порт у кибаны 5601, у эластика 9200.

    Переходя к Fluentd - это агент логов, который собирает логи из контейнеров и отправляет их
    в Elasticsearch. Мы можем сделать configmap 
    apiVersion: v1
    kind: ConfigMap
    metadata:
        name: fluentd-config
    data:
        fluent.conf: |
          <source>
            @type tail
            path /var/log/containers/*.log
            pos_file /var/log/fluentd-containers.log.pos
            tag "kubernetes.*"
            format json
            time_key time
          </source>

          <match kubernetes.**>
            @type elasticsearch
            host elasticsearch
            port 9200
            index_name fluentd
          </match>
    Этот файл конфигурации Fluentd указывает на то, что Fluentd должен собирать логи из всех
    контейнеров в /var/log/containers/ и отправлять их в Elasticsearch.

    либо в env daemon set это прописать, как пример fluent_elasticsearch_host(port, format,
    parser, time_format), также volumes, volumeMounts path: /var/log/containers/
```
